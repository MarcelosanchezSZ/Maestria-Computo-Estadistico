{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROYECTO FINAL\n",
    "### ALUMNO: MARCELO ALBERTO SANCHEZ ZARAGOZA\n",
    "\n",
    "\n",
    "# Ahora vemos cada participante por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from PIL.ImageChops import add, subtract, multiply, difference, screen\n",
    "import PIL.ImageStat as stat\n",
    "from skimage.io import imread, imsave, imshow, show, imread_collection, imshow_collection\n",
    "from skimage import color, viewer, exposure, img_as_float, data\n",
    "from skimage.transform import SimilarityTransform, warp, swirl\n",
    "from skimage.util import invert, random_noise, montage\n",
    "\n",
    "ruta1 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_1'\n",
    "ruta2 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_2'\n",
    "ruta3 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_3'\n",
    "ruta4 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_4'\n",
    "ruta5 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_5'\n",
    "ruta6 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_6'\n",
    "ruta7 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_7'\n",
    "ruta8 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_8'\n",
    "ruta9 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_9'\n",
    "ruta10 = r'C:\\Users\\Marcelo Sanchez\\Desktop\\Segundo semestre CIMAT\\Ciencia de Datos\\Proyecto\\datos_chinitas\\chinita_10'\n",
    "\n",
    "contenido1 = os.listdir(ruta1)\n",
    "contenido2 = os.listdir(ruta2)\n",
    "contenido3 = os.listdir(ruta3)\n",
    "contenido4 = os.listdir(ruta4)\n",
    "contenido5 = os.listdir(ruta5)\n",
    "contenido6 = os.listdir(ruta6)\n",
    "contenido7 = os.listdir(ruta7)\n",
    "contenido8 = os.listdir(ruta8)\n",
    "contenido9 = os.listdir(ruta9)\n",
    "contenido10 = os.listdir(ruta10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv('class.csv',encoding='latin1')\n",
    "#info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = info.iloc[0:19,3]\n",
    "y2 = info.iloc[19:38,3]\n",
    "y3 = info.iloc[38:57,3]\n",
    "y4 = info.iloc[57:74,3]\n",
    "y5 = info.iloc[74:92,3]\n",
    "y6 = info.iloc[92:110,3]\n",
    "y7 = info.iloc[110:127,3]\n",
    "y8 = info.iloc[127:145,3]\n",
    "y9 = info.iloc[145:163,3]\n",
    "y10 = info.iloc[163:180,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = [nombre for nombre in contenido2 if isfile(join(ruta2, nombre))]\n",
    "#archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota: para correr para cada una de las participantes hay que ir moviendo las variables: rutai, yi y contenidoi, donde i=1,...10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Todos_1 = []\n",
    "g_kernel = cv2.getGaborKernel((30, 30), np.pi/4, np.pi/2, 2.5, 0.8, 1.0, ktype=cv2.CV_32F)\n",
    "#g_kernel = cv2.getGaborKernel((5, 5), np.pi/1, np.pi/1, 5.5, 3.8, 1.0, ktype=cv2.CV_32F)\n",
    "for r in range(len(y2)):\n",
    "    img = cv2.imread(join(ruta2, archivos[r]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #con este nos dio un buen valor en maquinas de soporte vectorial\n",
    "    filtered_img = cv2.filter2D(img, cv2.CV_8UC3, g_kernel)\n",
    "    \n",
    "    #out = Gabor_process(img)\n",
    "    \n",
    "    l = []\n",
    "    p = filtered_img\n",
    "    #for i in range(40):\n",
    "    #    for j in range(190):\n",
    "    #        l.append(p[i+50,j+30])\n",
    "            \n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            l.append(p[i,j])\n",
    "    \n",
    "    #for i in range(256):\n",
    "     #   for j in range(256):\n",
    "      #      l.append(out[i,j])\n",
    "    \n",
    "    Todos_1.append(l)#filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65526</th>\n",
       "      <th>65527</th>\n",
       "      <th>65528</th>\n",
       "      <th>65529</th>\n",
       "      <th>65530</th>\n",
       "      <th>65531</th>\n",
       "      <th>65532</th>\n",
       "      <th>65533</th>\n",
       "      <th>65534</th>\n",
       "      <th>65535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.160784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.192157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.207843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.192157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.192157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.164706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.160784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.168627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.164706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.192157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.137255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.184314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.160784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.164706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 65536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6      \\\n",
       "0   0.192157  0.196078  0.192157  0.188235  0.192157  0.196078  0.200000   \n",
       "1   0.207843  0.203922  0.184314  0.172549  0.176471  0.180392  0.180392   \n",
       "2   0.184314  0.180392  0.176471  0.176471  0.192157  0.192157  0.172549   \n",
       "3   0.176471  0.180392  0.196078  0.211765  0.207843  0.192157  0.176471   \n",
       "4   0.196078  0.196078  0.192157  0.184314  0.188235  0.207843  0.211765   \n",
       "5   0.180392  0.184314  0.192157  0.200000  0.192157  0.176471  0.164706   \n",
       "6   0.203922  0.192157  0.176471  0.176471  0.164706  0.156863  0.168627   \n",
       "7   0.176471  0.176471  0.176471  0.164706  0.156863  0.156863  0.160784   \n",
       "8   0.152941  0.156863  0.160784  0.164706  0.164706  0.164706  0.168627   \n",
       "9   0.149020  0.152941  0.160784  0.172549  0.172549  0.172549  0.180392   \n",
       "10  0.141176  0.156863  0.176471  0.168627  0.156863  0.156863  0.164706   \n",
       "11  0.141176  0.141176  0.149020  0.152941  0.149020  0.152941  0.164706   \n",
       "12  0.137255  0.141176  0.152941  0.172549  0.188235  0.200000  0.203922   \n",
       "13  0.160784  0.164706  0.184314  0.203922  0.203922  0.188235  0.184314   \n",
       "14  0.176471  0.176471  0.168627  0.156863  0.152941  0.156863  0.168627   \n",
       "15  0.180392  0.180392  0.176471  0.164706  0.156863  0.164706  0.176471   \n",
       "16  0.168627  0.156863  0.156863  0.184314  0.203922  0.200000  0.188235   \n",
       "17  0.192157  0.188235  0.176471  0.160784  0.156863  0.160784  0.160784   \n",
       "18  0.176471  0.192157  0.211765  0.203922  0.180392  0.168627  0.176471   \n",
       "\n",
       "       7         8         9      ...     65526     65527     65528     65529  \\\n",
       "0   0.188235  0.168627  0.160784  ...  0.164706  0.184314  0.188235  0.192157   \n",
       "1   0.176471  0.188235  0.203922  ...  0.176471  0.180392  0.184314  0.188235   \n",
       "2   0.172549  0.184314  0.172549  ...  0.164706  0.188235  0.192157  0.180392   \n",
       "3   0.184314  0.196078  0.192157  ...  0.211765  0.207843  0.192157  0.184314   \n",
       "4   0.207843  0.211765  0.211765  ...  0.200000  0.184314  0.176471  0.172549   \n",
       "5   0.164706  0.180392  0.188235  ...  0.235294  0.223529  0.211765  0.223529   \n",
       "6   0.180392  0.180392  0.172549  ...  0.211765  0.215686  0.207843  0.207843   \n",
       "7   0.168627  0.172549  0.180392  ...  0.145098  0.129412  0.129412  0.137255   \n",
       "8   0.176471  0.184314  0.184314  ...  0.160784  0.156863  0.156863  0.156863   \n",
       "9   0.180392  0.180392  0.192157  ...  0.164706  0.156863  0.168627  0.168627   \n",
       "10  0.164706  0.152941  0.149020  ...  0.184314  0.176471  0.172549  0.172549   \n",
       "11  0.180392  0.196078  0.203922  ...  0.184314  0.180392  0.176471  0.172549   \n",
       "12  0.188235  0.168627  0.164706  ...  0.152941  0.164706  0.168627  0.172549   \n",
       "13  0.188235  0.176471  0.168627  ...  0.180392  0.188235  0.180392  0.168627   \n",
       "14  0.176471  0.180392  0.184314  ...  0.180392  0.184314  0.176471  0.168627   \n",
       "15  0.188235  0.200000  0.211765  ...  0.188235  0.184314  0.176471  0.164706   \n",
       "16  0.188235  0.200000  0.207843  ...  0.188235  0.192157  0.180392  0.172549   \n",
       "17  0.168627  0.176471  0.176471  ...  0.172549  0.180392  0.196078  0.200000   \n",
       "18  0.188235  0.184314  0.176471  ...  0.168627  0.168627  0.176471  0.180392   \n",
       "\n",
       "       65530     65531     65532     65533     65534     65535  \n",
       "0   0.188235  0.172549  0.160784  0.156863  0.160784  0.160784  \n",
       "1   0.200000  0.203922  0.196078  0.180392  0.176471  0.180392  \n",
       "2   0.176471  0.172549  0.164706  0.172549  0.184314  0.192157  \n",
       "3   0.188235  0.192157  0.203922  0.200000  0.200000  0.207843  \n",
       "4   0.164706  0.156863  0.149020  0.156863  0.180392  0.192157  \n",
       "5   0.227451  0.215686  0.211765  0.207843  0.200000  0.192157  \n",
       "6   0.196078  0.176471  0.160784  0.160784  0.160784  0.164706  \n",
       "7   0.156863  0.180392  0.188235  0.172549  0.160784  0.160784  \n",
       "8   0.164706  0.180392  0.184314  0.172549  0.168627  0.168627  \n",
       "9   0.160784  0.164706  0.172549  0.176471  0.172549  0.164706  \n",
       "10  0.172549  0.160784  0.145098  0.156863  0.184314  0.192157  \n",
       "11  0.156863  0.149020  0.145098  0.145098  0.141176  0.137255  \n",
       "12  0.172549  0.168627  0.156863  0.149020  0.141176  0.133333  \n",
       "13  0.156863  0.149020  0.152941  0.168627  0.180392  0.176471  \n",
       "14  0.168627  0.176471  0.180392  0.184314  0.184314  0.184314  \n",
       "15  0.164706  0.184314  0.188235  0.164706  0.156863  0.160784  \n",
       "16  0.164706  0.168627  0.188235  0.188235  0.180392  0.176471  \n",
       "17  0.196078  0.180392  0.160784  0.152941  0.168627  0.176471  \n",
       "18  0.176471  0.172549  0.176471  0.176471  0.168627  0.164706  \n",
       "\n",
       "[19 rows x 65536 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feo = np.array(Todos_1)\n",
    "#Feo.shape\n",
    "v = pd.DataFrame(Feo)\n",
    "v/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x13fe5ffd8e0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 418.125x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA # estandarizar y justificar\n",
    "import seaborn as sns\n",
    "\n",
    "sigma = 5.1 #0.8\n",
    "ncomp = len(y2)\n",
    "kpca = KernelPCA(n_components=ncomp, kernel='cosine', gamma=1/sigma) ##linear,poly,rbf,sigmoid-b,cosine,precomputed\n",
    "# rbf - \n",
    "# sigmoid - \n",
    "# cosine - 0.1 dio buen resultado en redes 0.78 y 0.81 en maquinas de soporte vectorial\n",
    "# linear 1.5\n",
    "# poly 5.5 y 1.1 con maquinas de sopote vectorial\n",
    "mesh_kpca = kpca.fit_transform(v/255) #X_sphere-estandar\n",
    "comps = pd.DataFrame(mesh_kpca)\n",
    "#comps\n",
    "\n",
    "g = {'PC':range(0,180), 'pc1':comps.iloc[:,4], 'pc2':comps.iloc[:,2], 'cl':info.iloc[:,3]}\n",
    "G = pd.DataFrame(g)\n",
    "#G\n",
    "#fig.add_subplot(321)\n",
    "sns.relplot(x='pc1', y='pc2', hue='cl',data=G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "datos_lim = pd.DataFrame(mesh_kpca)\n",
    "#datos_lim\n",
    "\n",
    "X_train, X_test = train_test_split(datos_lim, test_size=0.2, train_size=0.8, random_state=42)\n",
    "y_train, y_test = train_test_split(y1, test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.082372</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.070047</td>\n",
       "      <td>-0.066070</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>-0.010263</td>\n",
       "      <td>-0.032222</td>\n",
       "      <td>-0.069630</td>\n",
       "      <td>0.018320</td>\n",
       "      <td>-0.058897</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>-0.067010</td>\n",
       "      <td>-0.006427</td>\n",
       "      <td>-0.021916</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.133784</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>-0.084270</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>-0.054205</td>\n",
       "      <td>-0.079547</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>-0.060980</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>-0.031238</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>-0.055868</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.124468</td>\n",
       "      <td>-0.101664</td>\n",
       "      <td>-0.053760</td>\n",
       "      <td>0.064878</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>-0.019635</td>\n",
       "      <td>-0.014280</td>\n",
       "      <td>-0.037919</td>\n",
       "      <td>-0.017225</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>-0.088787</td>\n",
       "      <td>-0.015790</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>-0.004439</td>\n",
       "      <td>-0.054709</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.076844</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.083048</td>\n",
       "      <td>0.080479</td>\n",
       "      <td>-0.037935</td>\n",
       "      <td>0.069224</td>\n",
       "      <td>-0.073076</td>\n",
       "      <td>-0.003514</td>\n",
       "      <td>-0.009399</td>\n",
       "      <td>-0.015349</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>-0.020618</td>\n",
       "      <td>-0.003235</td>\n",
       "      <td>0.060208</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -0.082372  0.011270  0.040400  0.070047 -0.066070  0.082949 -0.010263   \n",
       "5  -0.133784  0.015511 -0.084270 -0.016518  0.002874 -0.054205 -0.079547   \n",
       "11  0.124468 -0.101664 -0.053760  0.064878  0.006832 -0.019635 -0.014280   \n",
       "1  -0.076844  0.033295  0.083048  0.080479 -0.037935  0.069224 -0.073076   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0  -0.032222 -0.069630  0.018320 -0.058897  0.022363  0.015603 -0.067010   \n",
       "5   0.037491  0.025550 -0.060980  0.013565  0.032858  0.003493 -0.031238   \n",
       "11 -0.037919 -0.017225  0.007620  0.012363  0.006352 -0.088787 -0.015790   \n",
       "1  -0.003514 -0.009399 -0.015349  0.082275 -0.020618 -0.003235  0.060208   \n",
       "\n",
       "          14        15        16        17   18  \n",
       "0  -0.006427 -0.021916 -0.002405  0.003950  0.0  \n",
       "5   0.034728 -0.055868 -0.014654  0.002864  0.0  \n",
       "11  0.012783  0.006098 -0.004439 -0.054709  0.0  \n",
       "1   0.004233  0.009513 -0.003113 -0.002059  0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ANG\n",
       "5     DIS\n",
       "11    NEU\n",
       "1     ANG\n",
       "Name: file.expression, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maquinas de soporte vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG       0.00      0.00      0.00         2\n",
      "         DIS       1.00      1.00      1.00         1\n",
      "         HAP       0.00      0.00      0.00         0\n",
      "         NEU       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.50      0.50      0.50         4\n",
      "weighted avg       0.50      0.50      0.50         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', C=2.5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_hat = clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred_hat))\n",
    "#plt.rcParams['figure.figsize'] = (8, 6)\n",
    "#disp1 = metrics.plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues)\n",
    "#disp1.ax_.set_title('Matriz de confusion. Sin normalizar',{'fontsize':15})\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG       0.00      0.00      0.00       2.0\n",
      "         DIS       0.00      0.00      0.00       1.0\n",
      "         HAP       0.00      0.00      0.00       0.0\n",
      "         NEU       0.00      0.00      0.00       1.0\n",
      "         SUR       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       4.0\n",
      "   macro avg       0.00      0.00      0.00       4.0\n",
      "weighted avg       0.00      0.00      0.00       4.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "hls = [10] #[10,3]\n",
    "# regularización\n",
    "a = 0.5\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=hls, \n",
    "                    random_state=0, alpha=a, max_iter=500).fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG       0.00      0.00      0.00         2\n",
      "         DIS       0.00      0.00      0.00         1\n",
      "         NEU       1.00      1.00      1.00         1\n",
      "         SAD       0.00      0.00      0.00         0\n",
      "         SUR       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.25         4\n",
      "   macro avg       0.20      0.20      0.20         4\n",
      "weighted avg       0.25      0.25      0.25         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\_empirical_covariance.py:88: UserWarning: Only one sample available. You may want to reshape your data array\n",
      "  warnings.warn(\"Only one sample available. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
